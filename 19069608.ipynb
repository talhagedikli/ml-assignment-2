{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ML-Assignment 2\n",
    "Muhammed Talha Gedikli - 19069608"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries and Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load important libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import make_regression\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from sklearn.linear_model import Ridge, Lasso\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.svm import SVC #note that this is non-linear SVM and its default is RBF\n",
    "from sklearn.datasets import make_regression #function used for generating synthetic datasets\n",
    "from sklearn.datasets import make_classification, make_blobs\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "\n",
    "# Import data\n",
    "train_data = pd.read_excel(\"./asg1_train_test_data/asg1_traindata.xlsx\")\n",
    "test_data = pd.read_excel(\"./asg1_train_test_data/asg1_testdata_without_prices.xlsx\")\n",
    "\n",
    "features_X = [\"Year\", \"Type\", \"Shift\", \"km\", \"Power\", \"Engine\", \"Seller\"]\n",
    "features_y = [\"Price\"]\n",
    "\n",
    "\n",
    "# Split data into features - prices\n",
    "X_data = train_data[features_X]\n",
    "y_data = train_data[features_y]\n",
    "\n",
    "\n",
    "# Split data into train and test sets\n",
    "# default is 75% / 25% train-test split\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X_data, y_data, random_state=735)\n",
    "\n",
    "# X_test = test_data[features_X]\n",
    "# y_test = test_data[features_y] Y values of test is not given\n",
    "# y_test = pd.read_csv(\"./Result.txt\", sep=\" \", header=None) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' \\n# Deal with categorical data\\nfrom sklearn.preprocessing import OneHotEncoder\\n\\n# Find the columns to deal with\\nobject_cols = [col for col in X_data.columns if X_data[col].dtype == \"object\"]\\n\\n# Apply one-hot encoder to each column with categorical data\\nOH_encoder = OneHotEncoder(handle_unknown=\\'ignore\\', sparse=False)\\nOH_cols_train = pd.DataFrame(OH_encoder.fit_transform(X_train[object_cols]))\\nOH_cols_test = pd.DataFrame(OH_encoder.fit_transform(X_test[object_cols]))\\n\\n# Give them column names (for example \"Shift_Auto, Shift_Manual\") instead of just integer column names (like \"0, 1, 2\")\\nOH_cols_train.columns = OH_encoder.get_feature_names_out(object_cols)\\nOH_cols_test.columns = OH_encoder.get_feature_names_out(object_cols)\\n\\n# One-hot encoding removed index; put it back\\nOH_cols_train.index = X_train.index\\nOH_cols_test.index = X_test.index\\n\\n# Remove categorical columns (will replace with one-hot encoding)\\nnum_X_train = X_train.drop(object_cols, axis=1)\\nnum_X_test = X_test.drop(object_cols, axis=1)\\n\\n# Add one-hot encoded columns to numerical features\\nOH_X_train = pd.concat([num_X_train, OH_cols_train], axis=1)\\nOH_X_test = pd.concat([num_X_test, OH_cols_test], axis=1)\\n'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "''' \n",
    "# Deal with categorical data\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "# Find the columns to deal with\n",
    "object_cols = [col for col in X_data.columns if X_data[col].dtype == \"object\"]\n",
    "\n",
    "# Apply one-hot encoder to each column with categorical data\n",
    "OH_encoder = OneHotEncoder(handle_unknown='ignore', sparse=False)\n",
    "OH_cols_train = pd.DataFrame(OH_encoder.fit_transform(X_train[object_cols]))\n",
    "OH_cols_test = pd.DataFrame(OH_encoder.fit_transform(X_test[object_cols]))\n",
    "\n",
    "# Give them column names (for example \"Shift_Auto, Shift_Manual\") instead of just integer column names (like \"0, 1, 2\")\n",
    "OH_cols_train.columns = OH_encoder.get_feature_names_out(object_cols)\n",
    "OH_cols_test.columns = OH_encoder.get_feature_names_out(object_cols)\n",
    "\n",
    "# One-hot encoding removed index; put it back\n",
    "OH_cols_train.index = X_train.index\n",
    "OH_cols_test.index = X_test.index\n",
    "\n",
    "# Remove categorical columns (will replace with one-hot encoding)\n",
    "num_X_train = X_train.drop(object_cols, axis=1)\n",
    "num_X_test = X_test.drop(object_cols, axis=1)\n",
    "\n",
    "# Add one-hot encoded columns to numerical features\n",
    "OH_X_train = pd.concat([num_X_train, OH_cols_train], axis=1)\n",
    "OH_X_test = pd.concat([num_X_test, OH_cols_test], axis=1)\n",
    "'''\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Handle With Categorical Data and Do Feature Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deal with categorical data\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "# Find the columns to deal with\n",
    "object_cols = [col for col in X_data.columns if X_data[col].dtype == \"object\"]\n",
    "\n",
    "# Apply one-hot encoder to each column with categorical data\n",
    "OH_encoder = OneHotEncoder(handle_unknown='ignore', sparse=False)\n",
    "OH_cols = pd.DataFrame(OH_encoder.fit_transform(X_data[object_cols]))\n",
    "\n",
    "# Give them column names (for example \"Shift_Auto, Shift_Manual\") instead of just integer column names (like \"0, 1, 2\")\n",
    "OH_cols.columns = OH_encoder.get_feature_names_out(object_cols)\n",
    "\n",
    "# One-hot encoding removed index; put it back\n",
    "OH_cols.index = X_data.index\n",
    "\n",
    "# Remove categorical columns (will replace with one-hot encoding)\n",
    "num_X_train = X_data.drop(object_cols, axis=1)\n",
    "\n",
    "# Add one-hot encoded columns to numerical features\n",
    "OH_X_data = pd.concat([num_X_train, OH_cols], axis=1)\n",
    "\n",
    "# Split data into train and test sets\n",
    "# default is 75% / 25% train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(OH_X_data, y_data, random_state=735)\n",
    "\n",
    "# Feature scaling\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Set scaler\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "##X_train, X_test, y_train, y_test = train_test_split(X_house, y_house)\n",
    "\n",
    "# Scale data\n",
    "X_train_scaled = scaler.fit_transform(X_train) # we use X_train to adjust/fit the scaler\n",
    "X_test_scaled  = scaler.transform(X_test) #use the same fit found above to transform X_test"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lineer Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R-squared score (training): 0.862\n",
      "R-squared score (test): 0.890\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Import required libraries\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# Prepare Data\n",
    "X_train, X_test, y_train, y_test = train_test_split(OH_X_data, y_data, random_state=735)\n",
    "\n",
    "# Define the model\n",
    "linr = LinearRegression().fit(X_train, y_train)\n",
    "\n",
    "# Make predictions using the testing set\n",
    "linr_y_pred = linr.predict(X_test)\n",
    "\n",
    "# Get and save the r2 values of the model\n",
    "linr_scores = {\n",
    "     \"r2_train\": linr.score(X_train, y_train),\n",
    "     \"r2_test\": linr.score(X_test, y_test)\n",
    "}\n",
    "\n",
    "# Print the scores\n",
    "print('R-squared score (training): {:.3f}'\n",
    "     .format(linr_scores['r2_train']))\n",
    "print('R-squared score (test): {:.3f}\\n'\n",
    "     .format(linr_scores['r2_test']))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Polynomial Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R-squared score (training): 0.969\n",
      "R-squared score (test): 0.805\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Import required libraries\n",
    "from sklearn.datasets import make_friedman1\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import make_regression #function used for generating synthetic datasets\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "# Make friedman\n",
    "X_F1, y_F1 = make_friedman1(n_samples = 100,\n",
    "                           n_features = 7, random_state=0)\n",
    "\n",
    "# # Prepare data for training and test\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X_F1, y_F1, random_state = 0)\n",
    "\n",
    "# Set polynomial features\n",
    "poly = PolynomialFeatures(degree=2)\n",
    "X_F1_poly = poly.fit_transform(X_F1)\n",
    "\n",
    "# Prepare data to make polynomial regression\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_F1_poly, y_F1, random_state = 0)\n",
    "polyr = LinearRegression().fit(X_train, y_train)\n",
    "\n",
    "# Get and save the r2 values of the model\n",
    "polr_scores = {\n",
    "     'r2_train': polyr.score(X_train, y_train),\n",
    "     'r2_test': polyr.score(X_test, y_test)\n",
    "}\n",
    "\n",
    "# Print r2 values\n",
    "print('R-squared score (training): {:.3f}'\n",
    "     .format(polr_scores['r2_train']))\n",
    "print('R-squared score (test): {:.3f}\\n'\n",
    "     .format(polr_scores['r2_test']))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ridge Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R-squared score (training): 0.862\n",
      "R-squared score (test): 0.890\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Import required libraries\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "# Prepare data \n",
    "X_train, X_test, y_train, y_test = train_test_split(OH_X_data, y_data, random_state=735)\n",
    "\n",
    "# Define model\n",
    "ridgr = Ridge(alpha=1).fit(X_train, y_train)\n",
    "\n",
    "# Predict y values for test set\n",
    "ridr_y_pred = ridgr.predict(X_test)\n",
    "\n",
    "# define model evaluation method\n",
    "# cv = RepeatedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "\n",
    "# ridr_r2 = r2_score(y_test, ridr_y_pred)\n",
    "\n",
    "# Get and save r2 values of the model\n",
    "ridgr_scores = {\n",
    "     'r2_train': ridgr.score(X_train, y_train),\n",
    "     'r2_test': ridgr.score(X_test, y_test)\n",
    "}\n",
    "\n",
    "# Print r2 values of the model\n",
    "print('R-squared score (training): {:.3f}'\n",
    "     .format(ridgr_scores['r2_train']))\n",
    "print('R-squared score (test): {:.3f}\\n'\n",
    "     .format(ridgr_scores['r2_test']))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lasso Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R-squared score (training): 0.862\n",
      "R-squared score (test): 0.890\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Import required libraries\n",
    "from sklearn.linear_model import Lasso\n",
    "\n",
    "# Prepare data\n",
    "X_train, X_test, y_train, y_test = train_test_split(OH_X_data, y_data, random_state=735)\n",
    "\n",
    "# Define model\n",
    "lassr = Lasso(alpha=10).fit(X_train, y_train)\n",
    "\n",
    "# Predict y values for test set\n",
    "lasr_y_pred = lassr.predict(X_test)\n",
    "\n",
    "# define model evaluation method\n",
    "# cv = RepeatedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "\n",
    "# lasr_r2 = r2_score(y_test, lasr_y_pred)\n",
    "\n",
    "# Get and save r2 scores of the model\n",
    "lassr_scores = {\n",
    "     'r2_train': lassr.score(X_train, y_train),\n",
    "     'r2_test': lassr.score(X_test, y_test)\n",
    "}\n",
    "\n",
    "# Print r2 scores\n",
    "print('R-squared score (training): {:.3f}'\n",
    "     .format(lassr_scores['r2_train']))\n",
    "print('R-squared score (test): {:.3f}\\n'\n",
    "     .format(lassr_scores['r2_test']))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R-squared score (training): 0.244\n",
      "R-squared score (test): 0.017\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\talha\\anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:198: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "c:\\Users\\talha\\anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "c:\\Users\\talha\\anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "c:\\Users\\talha\\anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n"
     ]
    }
   ],
   "source": [
    "# Import required libraries\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# Prepare data\n",
    "X_train, X_test, y_train, y_test = train_test_split(OH_X_data, y_data, random_state=735)\n",
    "\n",
    "# Define model\n",
    "knn = KNeighborsClassifier(n_neighbors = 5).fit(X_train, y_train)\n",
    "\n",
    "# Predict y values for test set\n",
    "knn_y_pred = knn.predict(X_test)\n",
    "\n",
    "# knn_r2 = r2_score(y_test, knn_y_pred)\n",
    "\n",
    "# Get and save r2 scores for the model\n",
    "knn_scores = {\n",
    "     'r2_train': knn.score(X_train, y_train),\n",
    "     'r2_test': knn.score(X_test, y_test)\n",
    "}\n",
    "\n",
    "# Print r2 scores\n",
    "print('R-squared score (training): {:.3f}'\n",
    "     .format(knn_scores['r2_train']))\n",
    "print('R-squared score (test): {:.3f}\\n'\n",
    "     .format(knn_scores['r2_test']))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\talha\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R-squared score (training): 0.244\n",
      "R-squared score (test): 0.017\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\talha\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "c:\\Users\\talha\\anaconda3\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but LinearSVC was fitted without feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\talha\\anaconda3\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but LinearSVC was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Import required libraries\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(OH_X_data, y_data, random_state=735)\n",
    "\n",
    "# Define and fit the model\n",
    "linsvc = LinearSVC(C=10).fit(X_train_scaled, y_train)\n",
    "\n",
    "# Get and save r2 scores for the model\n",
    "linsvc_scores = {\n",
    "    'r2_train': linsvc.score(X_train, y_train),\n",
    "    'r2_test': linsvc.score(X_test, y_test)\n",
    "}\n",
    "\n",
    "# Print r2 scores\n",
    "print('R-squared score (training): {:.3f}'\n",
    "     .format(knn_scores['r2_train']))\n",
    "print('R-squared score (test): {:.3f}\\n'\n",
    "     .format(knn_scores['r2_test']))\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Non-Linear SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\talha\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.01\n"
     ]
    }
   ],
   "source": [
    "# Import required libraries\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "svc = SVC(C=0.01, random_state=1).fit(X_train_scaled, y_train)\n",
    "print(round(svc.score(X_test_scaled, y_test), 3))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create excel file to export scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create excel file includeing scores etc"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export Results"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "2a5bab918500c3a27c83c494b562b57d38406af52f32585b0235d82cba8b1288"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
