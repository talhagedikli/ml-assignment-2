{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ML-Assignment 2\n",
    "Muhammed Talha Gedikli - 19069608"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries and Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load important libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import make_regression\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from sklearn.linear_model import Ridge, Lasso\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.svm import SVC #note that this is non-linear SVM and its default is RBF\n",
    "from sklearn.datasets import make_regression #function used for generating synthetic datasets\n",
    "from sklearn.datasets import make_classification, make_blobs\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "\n",
    "# Import data\n",
    "train_data = pd.read_excel(\"./asg1_train_test_data/asg1_traindata.xlsx\")\n",
    "test_data = pd.read_excel(\"./asg1_train_test_data/asg1_testdata_without_prices.xlsx\")\n",
    "\n",
    "test_data_without_prices = pd.read_excel(\"./asg1_train_test_data/asg1_testdata_without_prices.xlsx\")\n",
    "\n",
    "features_X = [\"Year\", \"Type\", \"Shift\", \"km\", \"Power\", \"Engine\", \"Seller\"]\n",
    "features_y = [\"Price\"]\n",
    "\n",
    "\n",
    "# Split data into features - prices\n",
    "X_data = train_data[features_X]\n",
    "y_data = train_data[features_y]\n",
    "\n",
    "X_data_without_prices = test_data_without_prices\n",
    "\n",
    "\n",
    "# Split data into train and test sets\n",
    "# default is 75% / 25% train-test split\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X_data, y_data, random_state=735)\n",
    "\n",
    "# X_test = test_data[features_X]\n",
    "# y_test = test_data[features_y] Y values of test is not given\n",
    "# y_test = pd.read_csv(\"./Result.txt\", sep=\" \", header=None) S"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' \\n# Deal with categorical data\\nfrom sklearn.preprocessing import OneHotEncoder\\n\\n# Find the columns to deal with\\nobject_cols = [col for col in X_data.columns if X_data[col].dtype == \"object\"]\\n\\n# Apply one-hot encoder to each column with categorical data\\nOH_encoder = OneHotEncoder(handle_unknown=\\'ignore\\', sparse=False)\\nOH_cols_train = pd.DataFrame(OH_encoder.fit_transform(X_train[object_cols]))\\nOH_cols_test = pd.DataFrame(OH_encoder.fit_transform(X_test[object_cols]))\\n\\n# Give them column names (for example \"Shift_Auto, Shift_Manual\") instead of just integer column names (like \"0, 1, 2\")\\nOH_cols_train.columns = OH_encoder.get_feature_names_out(object_cols)\\nOH_cols_test.columns = OH_encoder.get_feature_names_out(object_cols)\\n\\n# One-hot encoding removed index; put it back\\nOH_cols_train.index = X_train.index\\nOH_cols_test.index = X_test.index\\n\\n# Remove categorical columns (will replace with one-hot encoding)\\nnum_X_train = X_train.drop(object_cols, axis=1)\\nnum_X_test = X_test.drop(object_cols, axis=1)\\n\\n# Add one-hot encoded columns to numerical features\\nOH_X_train = pd.concat([num_X_train, OH_cols_train], axis=1)\\nOH_X_test = pd.concat([num_X_test, OH_cols_test], axis=1)\\n'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "''' \n",
    "# Deal with categorical data\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "# Find the columns to deal with\n",
    "object_cols = [col for col in X_data.columns if X_data[col].dtype == \"object\"]\n",
    "\n",
    "# Apply one-hot encoder to each column with categorical data\n",
    "OH_encoder = OneHotEncoder(handle_unknown='ignore', sparse=False)\n",
    "OH_cols_train = pd.DataFrame(OH_encoder.fit_transform(X_train[object_cols]))\n",
    "OH_cols_test = pd.DataFrame(OH_encoder.fit_transform(X_test[object_cols]))\n",
    "\n",
    "# Give them column names (for example \"Shift_Auto, Shift_Manual\") instead of just integer column names (like \"0, 1, 2\")\n",
    "OH_cols_train.columns = OH_encoder.get_feature_names_out(object_cols)\n",
    "OH_cols_test.columns = OH_encoder.get_feature_names_out(object_cols)\n",
    "\n",
    "# One-hot encoding removed index; put it back\n",
    "OH_cols_train.index = X_train.index\n",
    "OH_cols_test.index = X_test.index\n",
    "\n",
    "# Remove categorical columns (will replace with one-hot encoding)\n",
    "num_X_train = X_train.drop(object_cols, axis=1)\n",
    "num_X_test = X_test.drop(object_cols, axis=1)\n",
    "\n",
    "# Add one-hot encoded columns to numerical features\n",
    "OH_X_train = pd.concat([num_X_train, OH_cols_train], axis=1)\n",
    "OH_X_test = pd.concat([num_X_test, OH_cols_test], axis=1)\n",
    "'''\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Handle With Categorical Data and Do Feature Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deal with categorical data\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "# Find the columns to deal with\n",
    "object_cols = [col for col in X_data.columns if X_data[col].dtype == \"object\"]\n",
    "\n",
    "# Apply one-hot encoder to each column with categorical data\n",
    "OH_encoder = OneHotEncoder(handle_unknown='ignore', sparse=False)\n",
    "OH_cols = pd.DataFrame(OH_encoder.fit_transform(X_data[object_cols]))\n",
    "OH_X_without_prices_cols = pd.DataFrame(OH_encoder.fit_transform(X_data_without_prices[object_cols]))\n",
    "\n",
    "\n",
    "# Give them column names (for example \"Shift_Auto, Shift_Manual\") instead of just integer column names (like \"0, 1, 2\")\n",
    "OH_cols.columns = OH_encoder.get_feature_names_out(object_cols)\n",
    "OH_X_without_prices_cols.columns = OH_encoder.get_feature_names_out(object_cols)\n",
    "\n",
    "# One-hot encoding removed index; put it back\n",
    "OH_cols.index = X_data.index\n",
    "OH_X_without_prices_cols.index = X_data_without_prices.index\n",
    "\n",
    "# Remove categorical columns (will replace with one-hot encoding)\n",
    "num_X_train = X_data.drop(object_cols, axis=1)\n",
    "num_X_without_prices = X_data_without_prices.drop(object_cols, axis=1)\n",
    "\n",
    "# Add one-hot encoded columns to numerical features\n",
    "OH_X_data = pd.concat([num_X_train, OH_cols], axis=1)\n",
    "OH_X_data_without_prices = pd.concat([num_X_without_prices, OH_X_without_prices_cols], axis=1)\n",
    "\n",
    "# Split data into train and test sets\n",
    "# default is 75% / 25% train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(OH_X_data, y_data, random_state=735)\n",
    "\n",
    "# Feature scaling\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Set scaler\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "##X_train, X_test, y_train, y_test = train_test_split(X_house, y_house)\n",
    "\n",
    "# Scale data\n",
    "X_train_scaled = scaler.fit_transform(X_train) # we use X_train to adjust/fit the scaler\n",
    "X_test_scaled  = scaler.transform(X_test) #use the same fit found above to transform X_test# Scale data\n",
    "\n",
    "OH_X_data_scaled = scaler.fit_transform(OH_X_data) # we use X_train to adjust/fit the scaler"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lineer Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R-squared score (training): 0.862\n",
      "R-squared score (test): 0.890\n",
      "\n",
      "R-squared score (test): 0.866\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year</th>\n",
       "      <th>km</th>\n",
       "      <th>Power</th>\n",
       "      <th>Engine</th>\n",
       "      <th>Type_Diesel</th>\n",
       "      <th>Type_Gasoline</th>\n",
       "      <th>Type_LPG</th>\n",
       "      <th>Shift_Auto</th>\n",
       "      <th>Shift_Manual</th>\n",
       "      <th>Seller_Dealer</th>\n",
       "      <th>Seller_Owner</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2596</th>\n",
       "      <td>1997</td>\n",
       "      <td>207000</td>\n",
       "      <td>60</td>\n",
       "      <td>1389</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1929</th>\n",
       "      <td>1997</td>\n",
       "      <td>199000</td>\n",
       "      <td>60</td>\n",
       "      <td>1389</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>287</th>\n",
       "      <td>2002</td>\n",
       "      <td>130000</td>\n",
       "      <td>51</td>\n",
       "      <td>1200</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>892</th>\n",
       "      <td>2011</td>\n",
       "      <td>94230</td>\n",
       "      <td>90</td>\n",
       "      <td>1248</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>273</th>\n",
       "      <td>2008</td>\n",
       "      <td>194000</td>\n",
       "      <td>75</td>\n",
       "      <td>1248</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2847</th>\n",
       "      <td>2015</td>\n",
       "      <td>32654</td>\n",
       "      <td>75</td>\n",
       "      <td>1248</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1990</th>\n",
       "      <td>2000</td>\n",
       "      <td>183000</td>\n",
       "      <td>75</td>\n",
       "      <td>1199</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>557</th>\n",
       "      <td>2007</td>\n",
       "      <td>110000</td>\n",
       "      <td>80</td>\n",
       "      <td>1229</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2387</th>\n",
       "      <td>2005</td>\n",
       "      <td>135000</td>\n",
       "      <td>70</td>\n",
       "      <td>1248</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2740</th>\n",
       "      <td>2012</td>\n",
       "      <td>26000</td>\n",
       "      <td>75</td>\n",
       "      <td>1248</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>725 rows Ã— 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Year      km  Power  Engine  Type_Diesel  Type_Gasoline  Type_LPG  \\\n",
       "2596  1997  207000     60    1389          0.0            0.0       1.0   \n",
       "1929  1997  199000     60    1389          0.0            0.0       1.0   \n",
       "287   2002  130000     51    1200          0.0            1.0       0.0   \n",
       "892   2011   94230     90    1248          1.0            0.0       0.0   \n",
       "273   2008  194000     75    1248          1.0            0.0       0.0   \n",
       "...    ...     ...    ...     ...          ...            ...       ...   \n",
       "2847  2015   32654     75    1248          1.0            0.0       0.0   \n",
       "1990  2000  183000     75    1199          0.0            1.0       0.0   \n",
       "557   2007  110000     80    1229          0.0            1.0       0.0   \n",
       "2387  2005  135000     70    1248          1.0            0.0       0.0   \n",
       "2740  2012   26000     75    1248          1.0            0.0       0.0   \n",
       "\n",
       "      Shift_Auto  Shift_Manual  Seller_Dealer  Seller_Owner  \n",
       "2596         1.0           0.0            0.0           1.0  \n",
       "1929         1.0           0.0            1.0           0.0  \n",
       "287          1.0           0.0            1.0           0.0  \n",
       "892          0.0           1.0            1.0           0.0  \n",
       "273          0.0           1.0            0.0           1.0  \n",
       "...          ...           ...            ...           ...  \n",
       "2847         0.0           1.0            0.0           1.0  \n",
       "1990         0.0           1.0            0.0           1.0  \n",
       "557          0.0           1.0            0.0           1.0  \n",
       "2387         0.0           1.0            1.0           0.0  \n",
       "2740         0.0           1.0            0.0           1.0  \n",
       "\n",
       "[725 rows x 11 columns]"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import required libraries\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "\n",
    "# Prepare Data\n",
    "X_train, X_test, y_train, y_test = train_test_split(OH_X_data, y_data, random_state=735)\n",
    "\n",
    "# Define the model\n",
    "linr = LinearRegression().fit(X_train, y_train)\n",
    "\n",
    "kf5 = KFold(n_splits=5, shuffle=True)\n",
    "\n",
    "\n",
    "# Make predictions using the testing set\n",
    "linr_y_pred = linr.predict(X_test)\n",
    "\n",
    "# Get and save the r2 values of the model\n",
    "linr_scores = {\n",
    "     \"r2_train\": linr.score(X_train, y_train),\n",
    "     \"r2_test\": linr.score(X_test, y_test),\n",
    "     \"r2_cv\": cross_val_score(linr, X_train, y_train, cv=kf5, scoring=\"r2\")\n",
    "}\n",
    "\n",
    "# Print the scores\n",
    "print('R-squared score (training): {:.3f}'\n",
    "     .format(linr_scores['r2_train']))\n",
    "print('R-squared score (test): {:.3f}\\n'\n",
    "     .format(linr_scores['r2_test']))\n",
    "print('R-squared score (test): {:.3f}\\n'\n",
    "     .format(linr_scores['r2_cv'].mean()))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Polynomial Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R-squared score (training): 0.973\n",
      "R-squared score (test): 0.892\n",
      "\n",
      "R-squared score (test): 0.865\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Import required libraries\n",
    "from sklearn.datasets import make_friedman1\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import make_regression #function used for generating synthetic datasets\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "# Make friedman\n",
    "X_F1, y_F1 = make_friedman1(n_samples = 100,\n",
    "                           n_features = 7, random_state=0)\n",
    "\n",
    "# # Prepare data for training and test\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X_F1, y_F1, random_state = 0)\n",
    "\n",
    "# Set polynomial features\n",
    "poly = PolynomialFeatures(degree=2)\n",
    "X_F1_poly = poly.fit_transform(X_F1)\n",
    "\n",
    "# Prepare data to make polynomial regression\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_F1_poly, y_F1, random_state = 735)\n",
    "polyr = LinearRegression().fit(X_train, y_train)\n",
    "\n",
    "# Get and save the r2 values of the model\n",
    "polr_scores = {\n",
    "     'r2_train': polyr.score(X_train, y_train),\n",
    "     'r2_test': polyr.score(X_test, y_test),\n",
    "     'r2_cv': cross_val_score(polyr, X_train, y_train, cv=5, scoring=\"r2\")\n",
    "}\n",
    "\n",
    "# Print r2 values\n",
    "print('R-squared score (training): {:.3f}'\n",
    "     .format(polr_scores['r2_train']))\n",
    "print('R-squared score (test): {:.3f}\\n'\n",
    "     .format(polr_scores['r2_test']))\n",
    "print('R-squared score (test): {:.3f}\\n'\n",
    "     .format(linr_scores['r2_cv'].mean()))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ridge Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "r2_train: 0.862060104266035\n",
      "r2_test: 0.8899766788908589\n",
      "r2_cv: 0.8645629974549989\n",
      "\n",
      "\n",
      "20\n",
      "r2_train: 0.8620497965866654\n",
      "r2_test: 0.8899778785533\n",
      "r2_cv: 0.8645482224509509\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Import required libraries\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "# Prepare data \n",
    "X_train, X_test, y_train, y_test = train_test_split(OH_X_data, y_data, random_state=735)\n",
    "\n",
    "ridge_alpha = 1\n",
    "\n",
    "# Define model\n",
    "ridgr = Ridge(alpha=1).fit(X_train, y_train)\n",
    "\n",
    "# Predict y values for test set\n",
    "ridr_y_pred = ridgr.predict(X_test)\n",
    "best_alpha = 0\n",
    "# for this_alpha in [0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0, 2, 3, 4, 5, 6, 7, 8, 9, 10, 20, 30, 40]:\n",
    "for this_alpha in [10, 20]:\n",
    "     ridgr = Ridge(alpha = this_alpha).fit(X_train, y_train)\n",
    "     ridgr_scores = {\n",
    "          'r2_train': ridgr.score(X_train, y_train),\n",
    "          'r2_test': ridgr.score(X_test, y_test),\n",
    "          'r2_cv': cross_val_score(ridgr, X_train, y_train, cv=5, scoring=\"r2\").mean()\n",
    "     }\n",
    "     print(this_alpha)\n",
    "     for score_type, score_value in ridgr_scores.items():\n",
    "          print(score_type + \": \" + str(score_value))\n",
    "     print('\\n')\n",
    "\n",
    "# define model evaluation method\n",
    "# cv = RepeatedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "\n",
    "# ridr_r2 = r2_score(y_test, ridr_y_pred)\n",
    "\n",
    "# Get and save r2 values of the model\n",
    "ridgr_scores = {\n",
    "     'r2_train': ridgr.score(X_train, y_train),\n",
    "     'r2_test': ridgr.score(X_test, y_test),\n",
    "     'r2_cv': cross_val_score(ridgr, X_train, y_train, cv=5, scoring=\"r2\")\n",
    "}\n",
    "\n",
    "# Print r2 values of the model\n",
    "# print('R-squared score (training): {:.3f}'\n",
    "#      .format(ridgr_scores['r2_train']))\n",
    "# print('R-squared score (test): {:.3f}\\n'\n",
    "#      .format(ridgr_scores['r2_test']))\n",
    "# print('R-squared score (test): {:.3f}\\n'\n",
    "#      .format(ridgr_scores['r2_cv'].mean()))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lasso Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R-squared score (training): 0.862\n",
      "R-squared score (test): 0.890\n",
      "\n",
      "R-squared score (test): 0.865\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Import required libraries\n",
    "from sklearn.linear_model import Lasso\n",
    "\n",
    "# Prepare data\n",
    "X_train, X_test, y_train, y_test = train_test_split(OH_X_data, y_data, random_state=735)\n",
    "\n",
    "# Define model\n",
    "lassr = Lasso(alpha=10).fit(X_train, y_train)\n",
    "\n",
    "# Predict y values for test set\n",
    "lasr_y_pred = lassr.predict(X_test)\n",
    "\n",
    "# define model evaluation method\n",
    "# cv = RepeatedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "\n",
    "# lasr_r2 = r2_score(y_test, lasr_y_pred)\n",
    "\n",
    "# Get and save r2 scores of the model\n",
    "lassr_scores = {\n",
    "     'r2_train': lassr.score(X_train, y_train),\n",
    "     'r2_test': lassr.score(X_test, y_test),\n",
    "     'r2_cv': cross_val_score(lassr, X_train, y_train, cv=5, scoring=\"r2\")\n",
    "}\n",
    "\n",
    "# Print r2 scores\n",
    "print('R-squared score (training): {:.3f}'\n",
    "     .format(lassr_scores['r2_train']))\n",
    "print('R-squared score (test): {:.3f}\\n'\n",
    "     .format(lassr_scores['r2_test']))\n",
    "print('R-squared score (test): {:.3f}\\n'\n",
    "     .format(lassr_scores['r2_cv'].mean()))\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R-squared score (training): 0.253\n",
      "R-squared score (test): 0.026\n",
      "\n",
      "R-squared score (test): 0.865\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\talha\\anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "c:\\Users\\talha\\anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "c:\\Users\\talha\\anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n"
     ]
    }
   ],
   "source": [
    "# Import required libraries\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# Prepare data\n",
    "X_train, X_test, y_train, y_test = train_test_split(OH_X_data, y_data, random_state=0)\n",
    "\n",
    "# Define model\n",
    "knn = KNeighborsClassifier(n_neighbors = 5).fit(X_train, y_train.values.ravel())\n",
    "\n",
    "# Predict y values for test set\n",
    "knn_y_pred = knn.predict(X_test)\n",
    "\n",
    "# knn_r2 = r2_score(y_test, knn_y_pred)\n",
    "\n",
    "kf5 = KFold(n_splits=5, shuffle=True)\n",
    "\n",
    "# Get and save r2 scores for the model\n",
    "knn_scores = {\n",
    "     'r2_train': knn.score(X_train, y_train),\n",
    "     'r2_test': knn.score(X_test, y_test),\n",
    "     'r2_cv': cross_val_score(lassr, X_train, y_train, cv=kf5, scoring=\"r2\")\n",
    "}\n",
    "\n",
    "# Print r2 scores\n",
    "print('R-squared score (training): {:.3f}'\n",
    "     .format(knn_scores['r2_train']))\n",
    "print('R-squared score (test): {:.3f}\\n'\n",
    "     .format(knn_scores['r2_test']))\n",
    "print('R-squared score (test): {:.3f}\\n'\n",
    "     .format(knn_scores['r2_cv'].mean()))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\talha\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\Users\\talha\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "c:\\Users\\talha\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\Users\\talha\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "c:\\Users\\talha\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\Users\\talha\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "c:\\Users\\talha\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\Users\\talha\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "c:\\Users\\talha\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\Users\\talha\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "c:\\Users\\talha\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R-squared score (training): 0.253\n",
      "R-squared score (test): 0.026\n",
      "\n",
      "R-squared score (test): 0.865\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\talha\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Import required libraries\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(OH_X_data_scaled, y_data, random_state=735)\n",
    "\n",
    "# Define and fit the model\n",
    "linsvc = LinearSVC(C=10).fit(X_train, y_train)\n",
    "\n",
    "kf5 = KFold(n_splits=5, shuffle=True)\n",
    "\n",
    "# Get and save r2 scores for the model\n",
    "linsvc_scores = {\n",
    "    'r2_train': linsvc.score(X_train, y_train),\n",
    "    'r2_test': linsvc.score(X_test, y_test),\n",
    "    'r2_cv': cross_val_score(linsvc, X_train, y_train, cv=kf5, scoring=\"r2\")\n",
    "}\n",
    "\n",
    "# Print r2 scores\n",
    "print('R-squared score (training): {:.3f}'\n",
    "     .format(knn_scores['r2_train']))\n",
    "print('R-squared score (test): {:.3f}\\n'\n",
    "     .format(knn_scores['r2_test']))\n",
    "print('R-squared score (test): {:.3f}\\n'\n",
    "     .format(knn_scores['r2_cv'].mean()))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Non-Linear SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\talha\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.01\n"
     ]
    }
   ],
   "source": [
    "# Import required libraries\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "svc = SVC(C=0.01, random_state=1).fit(X_train_scaled, y_train)\n",
    "print(round(svc.score(X_test_scaled, y_test), 3))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create excel file to export scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>R2 Train</th>\n",
       "      <th>R2 Test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Linear Regression</th>\n",
       "      <td>0.862064</td>\n",
       "      <td>0.889969</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   R2 Train   R2 Test\n",
       "Linear Regression  0.862064  0.889969"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create excel file includeing scores etc\n",
    "table = pd.DataFrame(columns=[\"R2 Train\", \"R2 Test\"])\n",
    "table.loc[\"Linear Regression\"] = [linr_scores[\"r2_train\"], linr_scores[\"r2_test\"]]\n",
    "table"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[44905],\n",
       "       [28416],\n",
       "       [29227],\n",
       "       [20784],\n",
       "       [27799],\n",
       "       [48170],\n",
       "       [40406],\n",
       "       [29963],\n",
       "       [42176],\n",
       "       [18609],\n",
       "       [50335],\n",
       "       [18893],\n",
       "       [47547],\n",
       "       [37051],\n",
       "       [29294],\n",
       "       [37491],\n",
       "       [39428],\n",
       "       [30750],\n",
       "       [29632],\n",
       "       [53867],\n",
       "       [51918],\n",
       "       [22603],\n",
       "       [20648],\n",
       "       [50787],\n",
       "       [19187],\n",
       "       [ 7822],\n",
       "       [48668],\n",
       "       [30003],\n",
       "       [16093],\n",
       "       [21111],\n",
       "       [23870],\n",
       "       [47596],\n",
       "       [24220],\n",
       "       [50453],\n",
       "       [42055],\n",
       "       [26875],\n",
       "       [55576],\n",
       "       [36140],\n",
       "       [44110],\n",
       "       [21462],\n",
       "       [25235],\n",
       "       [28401],\n",
       "       [38270],\n",
       "       [16152],\n",
       "       [47326],\n",
       "       [50081],\n",
       "       [17946],\n",
       "       [43198],\n",
       "       [25164],\n",
       "       [27318],\n",
       "       [48815],\n",
       "       [52985],\n",
       "       [26460],\n",
       "       [43627],\n",
       "       [25845],\n",
       "       [30838],\n",
       "       [31301],\n",
       "       [58289],\n",
       "       [27299],\n",
       "       [45348],\n",
       "       [41330],\n",
       "       [28004],\n",
       "       [32472],\n",
       "       [30608],\n",
       "       [26322],\n",
       "       [54920],\n",
       "       [26046],\n",
       "       [54155],\n",
       "       [37329],\n",
       "       [44755],\n",
       "       [22823],\n",
       "       [16702],\n",
       "       [20848],\n",
       "       [41572],\n",
       "       [41618],\n",
       "       [32670],\n",
       "       [34018],\n",
       "       [29768],\n",
       "       [43411],\n",
       "       [33355],\n",
       "       [36083],\n",
       "       [28354],\n",
       "       [24395],\n",
       "       [28028],\n",
       "       [26706],\n",
       "       [25480],\n",
       "       [42141],\n",
       "       [26238],\n",
       "       [32785],\n",
       "       [25084],\n",
       "       [46684],\n",
       "       [50086],\n",
       "       [16665],\n",
       "       [38964]])"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Export Results\n",
    "price_predictions = linr.predict(OH_X_data_without_prices)\n",
    "price_predictions_int = price_predictions.astype(int)\n",
    "\n",
    "np.savetxt('test.txt', price_predictions_int)\n",
    "price_predictions_int\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "2a5bab918500c3a27c83c494b562b57d38406af52f32585b0235d82cba8b1288"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
